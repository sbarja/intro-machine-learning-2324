{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Figures/top_ML.png\" alt=\"Drawing\" style=\"width: 1100px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. EJERCICIO CLASIFICACIÓN DE USUARIOS SEGÚN SU CONSUMO\n",
    "\n",
    "Desarrollar un modelo de Aprendizaje Automático Supervisado para clasificar a los usuarios de una Compañía Minorista de Electricidad, según su perfil de consumo de electricidad por hora durante un día. Esta clasificación permitirá al personal de marketing de la compañía enviar ofertas personalizadas y apropiadas a estos dos tipos de perfiles de clientes: usuarios con un perfil de **consumo alto** y usuarios con un perfil de **consumo no alto**.\n",
    "\n",
    "Las columnas son: \n",
    "\n",
    "* (0) CUPs\n",
    "* (1) etiqueta\n",
    "* (2-26) consumo por hora (de h-0 a h-23).\n",
    "\n",
    "\n",
    "# Pasos para crear un modelo de machine learning\n",
    "\n",
    "<img src=\"Figures/Fases.png\" alt=\"Drawing\" style=\"width: 800px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 1. Importar librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #import pandas\n",
    "import matplotlib.pyplot as plt # import matplotlib to make graphs\n",
    "import seaborn as sns # import seaborn to make graphics\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Cargar el dataset y comprender los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b> Cargamos el dataset </b>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumption = pd.read_excel('Data/S4-clasificacion-consumos.xlsx')\n",
    "consumption.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b> Revisar cuantos grupos hay (etiquetas) </b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumption['etiqueta'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumption['CUPs'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset shape\n",
    "consumption.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formato de los datos\n",
    "dataset.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumption.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumption.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b> Falta algún dato? </b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumption.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Veamos cuántos usuarios hay de cada clase. ¿Tenemos un conjunto de datos equilibrado?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster==0\n",
    "print(\"Número etiqueta 0:\", consumption[consumption['etiqueta'] == 0]['etiqueta'].count())\n",
    "# cluster=1\n",
    "print(\"Número etiqueta 1:\", consumption[consumption['etiqueta'] == 1]['etiqueta'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = consumption['etiqueta'].value_counts().values\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nombramos las etiquetas para visualizarlas\n",
    "labels = ['Etiqueta 0', 'Etiqueta 1']\n",
    "values = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos un DataFrame\n",
    "df = pd.DataFrame({'Labels': labels, 'Values': x})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos la gráfica\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(x='Labels', y='Values', data=df, palette='viridis') \n",
    "plt.title('Contador del número de consumidores en cada clase')\n",
    "print('Número total de etiquetas: ', x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b> Creamos dos Dataframes (uno para cada clase) para analizarlos por separado </b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clients_0 = consumption[consumption['etiqueta']==0]\n",
    "clients_1 = consumption[consumption['etiqueta']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clients_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average hourly consumption comparison\n",
    "print(\"Media horaria de potencia CLASE/ETIQUETA 0: \", clients_0.drop(['CUPs','etiqueta'], axis=1).mean(axis=1).mean(), 'kW')\n",
    "print(\"Media horaria de potencia CLASE/ETIQUETA 1: \", clients_1.drop(['CUPs','etiqueta'], axis=1).mean(axis=1).mean(), 'kW')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-success\">\n",
    "    <b> Eliminar la columna 'etiqueta' para graficar las diferentes curvas de consumo. </b>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0 = clients_0.drop(['etiqueta'], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-success\">\n",
    "    <b> Haz que la \"columna CUPs\" sea el índice (ya que cada fila tiene un valor diferente e identifica al SM). </b>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0.set_index(['CUPs'], inplace=True)\n",
    "\n",
    "# Transpose the matrix, for ease of plotting\n",
    "df_0 = df_0.T\n",
    "\n",
    "# We change the name of the index to \"hour\".\n",
    "df_0.index.name = 'hour'\n",
    "df_0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = clients_1.drop(['etiqueta'], axis=1)\n",
    "df_1.set_index(['CUPs'], inplace=True)\n",
    "df_1 = df_1.T\n",
    "df_1.index.name = 'hour'\n",
    "df_1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-success\">\n",
    "    <b> Obtenemos una lista con las columnas de los dos dataframes para tener los CUPs de la clase 0 y la clase 1. </b>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cups_0 = df_0.columns\n",
    "cups_1 = df_1.columns\n",
    "\n",
    "print(cups_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-success\">\n",
    "    <b> Graficamos. </b>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(20,8))\n",
    "\n",
    "# Create a loop where cups takes each of the strings in the cups_0 list.\n",
    "for cups in cups_0:\n",
    "    # 'lightcoral' indicates the color (https://matplotlib.org/2.1.1/gallery/color/named_colors.html)\n",
    "    # linewidth sets the line width and alpha the transparency\n",
    "    plt.plot(df_0[cups], 'lightcoral', linewidth=1, alpha=0.4)\n",
    "for cups in cups_1:\n",
    "    plt.plot(df_1[cups], 'green', linewidth=1, alpha=0.4)\n",
    "\n",
    "    # X axis displays the hours\n",
    "plt.xticks(df_0.index)\n",
    "plt.xlabel('Hours', fontsize=16)\n",
    "plt.ylabel('Consumers consumption [kWh]', fontsize=16)\n",
    "\n",
    "plt.margins(x=0, y=0)\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b> Agregamos el consumo promedio para distinguir más claramente las diferencias entre los clusters </b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0['mean'] = df_0.mean(axis=1)\n",
    "df_1['mean'] = df_1.mean(axis=1)\n",
    "df_1.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b> Creamos los mismos gráficos que antes, agregando las curvas promedio de las dos clases (0/1) con más opacidad (alpha). </b>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(20,8))\n",
    "for cups in cups_0:\n",
    "    plt.plot(df_0[cups], 'lightcoral', linewidth=1, alpha=0.2)\n",
    "\n",
    "for cups in cups_1:\n",
    "    plt.plot(df_1[cups], 'green', linewidth=1, alpha=0.2)\n",
    "\n",
    "plt.plot(df_0['mean'], 'tomato', linestyle='dashed', linewidth=4, alpha=1)    \n",
    "plt.plot(df_1['mean'], 'green', linestyle='dashed', linewidth=4, alpha=1)\n",
    "\n",
    "plt.xticks(df_0.index)\n",
    "plt.margins(x=0, y=0)\n",
    "plt.xlabel('Hours', fontsize=16)\n",
    "plt.ylabel('Consumers consumption [kWh]', fontsize=16)\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b> Correlación entre las características y la etiqueta. </b>\n",
    "</div>\n",
    "\n",
    "\n",
    "<img src=\"Figures/coef-correlacion.jpg\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "\n",
    "\n",
    "<img src=\"Figures/correlation.png\" alt=\"Drawing\" style=\"width: 400px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(18, 10))\n",
    "\n",
    "# Create the correlation matrix after eliminating the CUPs column since it does not provide information in this case.\n",
    "corr = consumption.drop(['CUPs'],axis=1).corr()\n",
    "\n",
    "# Create a heat map to visually detect the correlation between the columns.\n",
    "sns.heatmap(corr, cmap=\"coolwarm\", vmin=-1, vmax=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b> Creamos un boxplot para detectar la variabilidad en cada clase. </b>\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clients_0: 'non-high consumption'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating boxplot\n",
    "plt.subplots(figsize=(15, 8))\n",
    "bp = clients_0.drop(['CUPs'],axis=1).boxplot(column=list(clients_0.drop(['CUPs'],axis=1).columns))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clients_1: 'high consumption'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(15, 8))\n",
    "bp = clients_1.drop(['CUPs'],axis=1).boxplot(column=list(clients_1.drop(['CUPs'],axis=1).columns))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Preparamos los datos\n",
    "## Feature selection/ engineering\n",
    "Crear algunas nuevas características/features que pueden ser interesantes para reducir la dimensionalidad del problema y mejorar el rendimiento del algoritmo. Las nuevas características se basarán en el consumo por hora (media, máximo, desviación estándar, media (13h-21h)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b> Creear nuevas características que puedan ser interesantes para reducir la dimensionalidad del problema y mejorar el rendimiento del algoritmo. \"Máximo\" y \"mínimo\". </b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hours = list(consumption.drop(['CUPs', 'etiqueta'], axis=1))\n",
    "\n",
    "# Basic examples (please note that some of these characteristics may have a high correlation between them)\n",
    "consumption['average'] = consumption[hours].mean(axis=1)\n",
    "consumption['max'] = consumption[hours].max(axis=1)\n",
    "consumption['min'] = consumption[hours].min(axis=1)\n",
    "consumption['std'] = consumption[hours].std(axis=1)\n",
    "\n",
    "# Example minmax\n",
    "minmax = []\n",
    "# iteramos fila a fila en nuestro df\n",
    "for index, row in consumption.iterrows():\n",
    "    # si el mínimo es 0, fijaremos minmax a 0, para evitar una indeterminación 0/0\n",
    "    if row['min'] == 0:\n",
    "        minmax.append(0)\n",
    "    else:\n",
    "        minmax.append(row['min']/row['max'])\n",
    "consumption['minmax'] = minmax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example average over a period of time. We have seen that between 13h and 21h there is a greater difference between clusters. \n",
    "peak_hours = ['h-' + str(x) for x in range(13,21)]\n",
    "consumption['peak_hours'] = consumption[peak_hours].mean(axis=1)\n",
    "\n",
    "consumption.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b> Comprobar la correlation matrix otra vez. </b>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(20, 10))\n",
    "corr = consumption.drop(['CUPs'],axis=1).corr()\n",
    "sns.heatmap(corr, cmap=\"coolwarm\", vmin=-1, vmax=1)\n",
    "\n",
    "# Negative correlation (close to -1) is also interesting, as may be the case for minmax and cluster."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Dividir los datos\n",
    "\n",
    "Shuffle=True indica que los datos se dividen aleatoriamente entre entrenamiento y prueba. Esto reduce la varianza y evita que el modelo se sobreajuste.\n",
    "\n",
    "<img src=\"Figures/train-val-test.png\" alt=\"Drawing\" style=\"width: 800px;\"/>\n",
    "\n",
    "\n",
    "<img src=\"Figures/X_y.png\" alt=\"Drawing\" style=\"width: 800px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = consumption.drop(['etiqueta'], axis=1) \n",
    "y = consumption['etiqueta']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "test_size = 0.2 # percentage of the input data that I will use to validate the model\n",
    "random_state=0\n",
    "# Divide the data into training, validation and test data.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state,\n",
    "                                                    shuffle=True)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=test_size, random_state=random_state,\n",
    "                                                    shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Construcción y evaluación de algoritmos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b> Añadir algoritmos de clasificación </b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "num_folds = 15\n",
    "error_metrics = {'balanced_accuracy'}\n",
    "models = {('LR', LogisticRegression()),\n",
    "           ('RF', RandomForestClassifier())}\n",
    "\n",
    "results = [] # stores the results of the evaluation metrics\n",
    "names = [] # name of each algorithm\n",
    "msg = [] # print the summary of the cross-validation method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "# Entreno con validación cruzada\n",
    "for scoring in error_metrics:\n",
    "    print('Classification evaluation metric: ', scoring)\n",
    "    for name, model in models:\n",
    "        print('Model ', name)\n",
    "        cross_validation = StratifiedShuffleSplit(n_splits=num_folds, random_state=0)\n",
    "        cv_results = cross_val_score(model, X_train, y_train, cv=cross_validation, scoring=scoring)\n",
    "        results.append(cv_results)\n",
    "        names.append(name)\n",
    "        resume = (name, cv_results.mean(), cv_results.std())\n",
    "        msg.append(resume)\n",
    "    print(msg)\n",
    "\n",
    "    # Comparar resultados entre algoritmos\n",
    "    fig = plt.figure()\n",
    "    fig.suptitle('Comparison of algorithms with evaluation metrics: %s' %scoring)\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_xlabel('Candidate models')\n",
    "    ax.set_ylabel('%s' %scoring)\n",
    "    plt.boxplot(results)\n",
    "    ax.set_xticklabels(names)\n",
    "    plt.show()\n",
    "\n",
    "    results = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Ajuste de Hiperparámetros del mejor(es) modelo.\n",
    "\n",
    "Pasos para realizar la ajuste hiperparamétrico de los parámetros:\n",
    "\n",
    "* Métrica a optimizar: balanced accuracy\n",
    "* Definir rangos de parámetros de búsqueda: params\n",
    "* Asignar un método de validación: StratifiedShuffleSplit (n_splits = 10).\n",
    "* Entrenar con los datos de validación: X_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RandomForestClassifier\n",
    "model = RandomForestClassifier()\n",
    "params = {\n",
    "     'n_estimators': [100, 600, 1000], #default=100\n",
    "     'min_samples_split': [2,5], #default=2\n",
    " }\n",
    "scoring='balanced_accuracy'\n",
    "cross_validation = StratifiedShuffleSplit(n_splits=10, random_state=0)\n",
    "my_cv = cross_validation.split(X_val, y_val)\n",
    "gsearch = GridSearchCV(estimator=model, param_grid=params, scoring=scoring, cv=my_cv)\n",
    "gsearch.fit(X_val, y_val)\n",
    "\n",
    "print(\"Best results: %f using the following hyperparameters %s\" % (gsearch.best_score_, gsearch.best_params_))\n",
    "means = gsearch.cv_results_['mean_test_score']\n",
    "stds = gsearch.cv_results_['std_test_score']\n",
    "params = gsearch.cv_results_['params']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Evaluación final del modelo.\n",
    "Evaluation metrics:\n",
    "  * 1. Confusion matrix\n",
    "  * 2. Matthews Coefficient (MCC)\n",
    "  * 3. ROC / AUC curve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clf_model = RandomForestClassifier(min_samples_split=2,  n_estimators=600)\n",
    "clf_model.fit(X_train,y_train)  # The RF model is trained\n",
    "y_predict = clf_model.predict(X_test)  # Predictions are calculated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b> Imprimir el ranking de importancia de las características de entrada. </b>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Feature importances extraction\n",
    "feature_importances = clf_model.feature_importances_\n",
    "\n",
    "# If you have actual feature names, use them here. Otherwise, generate as follows:\n",
    "feature_names = feature_names = X_train.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting the feature importances in descending order\n",
    "sorted_idx = np.argsort(feature_importances)[::-1]\n",
    "\n",
    "# Creating the plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.title('Feature Importances')\n",
    "plt.bar(range(len(feature_importances)), feature_importances[sorted_idx], align='center')\n",
    "plt.xticks(range(len(feature_importances)), np.array(feature_names)[sorted_idx], rotation=90)\n",
    "plt.xlim([-1, X_train.shape[1]])  # set x limits to feature range\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b> 1. Matriz de Confusión </b>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
    "\n",
    "confusion_matrix = confusion_matrix(y_test, y_predict)\n",
    "print(classification_report(y_test, y_predict))\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico no normalizado de la martiz de confusión\n",
    "\n",
    "# Plotting the confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b> 2. Matthews Coefficient (MCC) </b>\n",
    "</div>\n",
    "\n",
    "El MCC utiliza coeficientes de correlación entre -1 y +1.\n",
    "* El coeficiente +1 representa una predicción perfecta.\n",
    "* El coeficiente 0 representa una predicción media aleatoria.\n",
    "* El coeficiente -1 representa una predicción inversa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "matthews_corrcoef(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b> 3. ROC/AUC curve </b>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"Figures/rocteoria.png\" alt=\"Drawing\" style=\"width: 800px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# Calcular ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_predict)\n",
    "\n",
    "# Calcular AUC\n",
    "auc = roc_auc_score(y_test, y_predict)\n",
    "print(\"AUC: {:.2f}\".format(auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficar la curva ROC\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.00])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "widgets": {
   "state": {},
   "version": "1.1.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
